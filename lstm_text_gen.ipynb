{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "# to later delete \"optimizer_weights\" part of the model weights\n",
    "# due to errors that occur when training on gpu and testing on cpu\n",
    "import h5py\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists from the lyrics for 57650 songs. The data has been acquired from LyricsFreak through scraping. Then some very basic work has been done on removing inconvenient data: non-English lyrics, extremely short and extremely long lyrics, lyrics with non-ASCII symbols. The dataset contains 4 columns:\n",
    "\n",
    "* Artist\n",
    "* Song Name\n",
    "* Link to a webpage with the song (for reference). This is to be concatenated with http://www.lyricsfreak.com to form a real URL.\n",
    "* Lyrics of the song, unmodified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/songdata.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 68056106\n",
      "Example text: look at her face, it's a wonderful face  \n",
      "and it means something special to me  \n",
      "look at the way that she smiles when she sees me  \n",
      "how lucky can one fellow be?  \n",
      "  \n",
      "she's just my kind of girl, she makes me feel fine  \n",
      "who could ever believe that she could be mine?  \n",
      "she's just my kind of girl, with\n"
     ]
    }
   ],
   "source": [
    "corpus = data['text'].str.cat(sep='\\n').lower()\n",
    "print('Corpus length:', len(corpus))\n",
    "print('Example text:', corpus[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated corpus length: 1000000\n"
     ]
    }
   ],
   "source": [
    "# truncating the corpus\n",
    "# since it is going to take too long to train\n",
    "corpus = corpus[:1000000]\n",
    "print('Truncated corpus length:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 50\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# creating a character vocabulary\n",
    "chars = sorted(list(set(corpus)))\n",
    "print('Total chars:', len(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating lookup dictionaries\n",
    "char_to_ind = dict((c, i) for i, c in enumerate(chars))\n",
    "ind_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40 # the window size\n",
    "step = 3 # step of the window\n",
    "sentences = []\n",
    "next_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sentences: (333320,)\n",
      "[\"look at her face, it's a wonderful face \"\n",
      " \"k at her face, it's a wonderful face  \\na\"\n",
      " \"t her face, it's a wonderful face  \\nand \" ...,\n",
      " \"t that we're less worse  \\n  \\ntears are n\"\n",
      " \"hat we're less worse  \\n  \\ntears are not \"\n",
      " \" we're less worse  \\n  \\ntears are not eno\"]\n",
      "[' ' 'n' 'i' ..., 'o' 'e' 'u']\n"
     ]
    }
   ],
   "source": [
    "# sentences as features, next chars as labels\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen]) # range from current index i for max length characters \n",
    "    next_chars.append(corpus[i + maxlen]) # the next character after that \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "print('Shape of sentences:', sentences.shape)\n",
    "print(sentences)\n",
    "print(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer encoded X: [192992 181993 264233 ..., 266428 157152  73624]\n",
      "Integer encoded y: [ 1 37 32 ..., 38 28 44]\n"
     ]
    }
   ],
   "source": [
    "# convert each character to categorical numbers\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_X = label_encoder.fit_transform(sentences)\n",
    "integer_encoded_y = label_encoder.fit_transform(next_chars)\n",
    "\n",
    "print('Integer encoded X:', integer_encoded_X)\n",
    "print('Integer encoded y:', integer_encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-164a893bb629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minteger_encoded_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0monehot_encoded_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minteger_encoded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_encoded_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# one-hot encode each categorical number\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded_X = integer_encoded_X.reshape(len(integer_encoded_X), 1)\n",
    "onehot_encoded_X = onehot_encoder.fit_transform(integer_encoded_X)\n",
    "\n",
    "integer_encoded_y = integer_encoded_y.reshape(len(integer_encoded_y), 1)\n",
    "onehot_encoded_y = onehot_encoder.fit_transform(integer_encoded_y)\n",
    "\n",
    "\n",
    "print(onehot_encoded_X, onehot_encoded_y)\n",
    "\n",
    "X = onehot_encoded_X\n",
    "y = onehot_encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding the input values wrapped in a separate function,\n",
    "# since the dataset length causes the memory error (on my machine) when converting all at once\n",
    "def encode(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_to_ind[char]] = 1\n",
    "        y[i, char_to_ind[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "X, y = encode(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 98,098\n",
      "Trainable params: 98,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training checkpoints\n",
    "filepath=\"weights{epoch:02d}-{loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 2.1995Epoch 00000: loss improved from inf to 2.19947, saving model to weights00-2.1995.h5\n",
      "333320/333320 [==============================] - 163s - loss: 2.1995   \n",
      "Epoch 2/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.8032Epoch 00001: loss improved from 2.19947 to 1.80316, saving model to weights01-1.8032.h5\n",
      "333320/333320 [==============================] - 151s - loss: 1.8032   \n",
      "Epoch 3/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.6684Epoch 00002: loss improved from 1.80316 to 1.66841, saving model to weights02-1.6684.h5\n",
      "333320/333320 [==============================] - 151s - loss: 1.6684   \n",
      "Epoch 4/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.5845Epoch 00003: loss improved from 1.66841 to 1.58450, saving model to weights03-1.5845.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.5845   \n",
      "Epoch 5/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.5242Epoch 00004: loss improved from 1.58450 to 1.52414, saving model to weights04-1.5241.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.5241   \n",
      "Epoch 6/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4780Epoch 00005: loss improved from 1.52414 to 1.47796, saving model to weights05-1.4780.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.4780   \n",
      "Epoch 7/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4408Epoch 00006: loss improved from 1.47796 to 1.44082, saving model to weights06-1.4408.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.4408   \n",
      "Epoch 8/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4091Epoch 00007: loss improved from 1.44082 to 1.40910, saving model to weights07-1.4091.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.4091   \n",
      "Epoch 9/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3829Epoch 00008: loss improved from 1.40910 to 1.38295, saving model to weights08-1.3829.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.3829   \n",
      "Epoch 10/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3605Epoch 00009: loss improved from 1.38295 to 1.36045, saving model to weights09-1.3605.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.3605   \n",
      "Epoch 11/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3393Epoch 00010: loss improved from 1.36045 to 1.33930, saving model to weights10-1.3393.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.3393   \n",
      "Epoch 12/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3214Epoch 00011: loss improved from 1.33930 to 1.32136, saving model to weights11-1.3214.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.3214   \n",
      "Epoch 13/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3050Epoch 00012: loss improved from 1.32136 to 1.30503, saving model to weights12-1.3050.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.3050   \n",
      "Epoch 14/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2902Epoch 00013: loss improved from 1.30503 to 1.29025, saving model to weights13-1.2903.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2903   \n",
      "Epoch 15/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2766Epoch 00014: loss improved from 1.29025 to 1.27663, saving model to weights14-1.2766.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2766   \n",
      "Epoch 16/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2646Epoch 00015: loss improved from 1.27663 to 1.26462, saving model to weights15-1.2646.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2646   \n",
      "Epoch 17/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2526Epoch 00016: loss improved from 1.26462 to 1.25264, saving model to weights16-1.2526.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2526   \n",
      "Epoch 18/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2420Epoch 00017: loss improved from 1.25264 to 1.24197, saving model to weights17-1.2420.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2420   \n",
      "Epoch 19/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2311Epoch 00018: loss improved from 1.24197 to 1.23111, saving model to weights18-1.2311.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2311   \n",
      "Epoch 20/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2220Epoch 00019: loss improved from 1.23111 to 1.22202, saving model to weights19-1.2220.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2220   \n",
      "Epoch 21/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2136Epoch 00020: loss improved from 1.22202 to 1.21358, saving model to weights20-1.2136.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.2136   \n",
      "Epoch 22/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2054Epoch 00021: loss improved from 1.21358 to 1.20540, saving model to weights21-1.2054.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.2054   \n",
      "Epoch 23/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1979Epoch 00022: loss improved from 1.20540 to 1.19790, saving model to weights22-1.1979.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1979   \n",
      "Epoch 24/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1902Epoch 00023: loss improved from 1.19790 to 1.19020, saving model to weights23-1.1902.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.1902   \n",
      "Epoch 25/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1829Epoch 00024: loss improved from 1.19020 to 1.18288, saving model to weights24-1.1829.h5\n",
      "333320/333320 [==============================] - 148s - loss: 1.1829   \n",
      "Epoch 26/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1766Epoch 00025: loss improved from 1.18288 to 1.17660, saving model to weights25-1.1766.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1766   \n",
      "Epoch 27/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1707Epoch 00026: loss improved from 1.17660 to 1.17073, saving model to weights26-1.1707.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1707   \n",
      "Epoch 28/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1649Epoch 00027: loss improved from 1.17073 to 1.16486, saving model to weights27-1.1649.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1649   \n",
      "Epoch 29/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1591Epoch 00028: loss improved from 1.16486 to 1.15906, saving model to weights28-1.1591.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1591   \n",
      "Epoch 30/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.1538Epoch 00029: loss improved from 1.15906 to 1.15377, saving model to weights29-1.1538.h5\n",
      "333320/333320 [==============================] - 149s - loss: 1.1538   \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 128\n",
    "\n",
    "trained = model.fit(X, y, batch_size, epochs=30, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: run this if the model is trained on gpu but being tested on cpu\n",
    "# RUN ONCE FOR A FILE\n",
    "f = h5py.File('weights29-1.1538.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length: 40\n",
      "Predictions per char in vocabulary [[  1.71119809e-05   3.55375111e-02   3.41021769e-06   3.78997298e-04\n",
      "    3.98959179e-04   2.78970995e-03   1.24004885e-06   1.13178930e-05\n",
      "    1.01340382e-04   6.87545935e-06   2.05232845e-06   1.37025680e-04\n",
      "    1.05412648e-04   4.65848598e-06   5.19655487e-06   6.08608207e-06\n",
      "    2.02593510e-04   1.84048508e-06   5.33222192e-06   1.71361007e-05\n",
      "    3.25404312e-06   5.19605201e-05   5.64325564e-05   4.10753501e-07\n",
      "    1.92759149e-02   9.45081562e-02   3.21600474e-02   2.19398439e-02\n",
      "    1.06698321e-02   3.52355726e-02   4.42303494e-02   9.67846066e-02\n",
      "    3.11897211e-02   9.77126230e-03   2.41910759e-02   1.64146617e-01\n",
      "    1.20490817e-02   3.38718249e-03   6.52648415e-03   3.67834084e-02\n",
      "    1.99042726e-03   1.12015735e-02   1.44536838e-01   7.38101080e-02\n",
      "    7.27118109e-04   6.28432550e-04   3.59937400e-02   4.56165872e-05\n",
      "    4.82902229e-02   8.08818659e-05]]\n"
     ]
    }
   ],
   "source": [
    "# example test phrase\n",
    "sentence = 'wise men say only fools rush in but can '\n",
    "sentence = sentence.lower()\n",
    "print('Sentence length:', len(sentence))\n",
    "\n",
    "# construct a vector from an example phrase\n",
    "x = np.zeros((1, maxlen, len(chars)))\n",
    "for i, char in enumerate(sentence):\n",
    "    x[0, i, char_to_ind[char]] = 1.\n",
    "    \n",
    "# load trained weights\n",
    "model = load_model('weights29-1.1538.h5')\n",
    "\n",
    "\n",
    "print('Predictions per char in vocabulary', model.predict(x, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: adding randomness for choosing predicted characters\n",
    "def sample(preds, temperature):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.8\n",
      "wise men say only fools rush in but can be sall  \n",
      "i have the smappeat leed me  \n",
      "  \n",
      "shine chasing two the man and then you ever fidds  \n",
      "home is so on the tears  \n",
      "freemonts my show  \n",
      "i want to midnide me and the strousing for a get a boy trought  \n",
      "give me on the tile is just only money, jeen, more that spine mingin' rifer  \n",
      "the mount, and the selt time we till in the couls sidenth  \n",
      "there's no breath me to the bould say  \n",
      "goodollin' at the even cake the morning  \n",
      "it's slowd when prectory  \n",
      "and but there's too find  \n",
      "i stop myse the dest\n"
     ]
    }
   ],
   "source": [
    "# temperature defines randomness rate for using predictions\n",
    "temperature = 0.8\n",
    "print('Temperature: ', temperature)\n",
    "\n",
    "generated = ''\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "# predicting next 500 chars\n",
    "for i in range(500):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t, char_to_ind[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = ind_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    window = window[1:] + next_char\n",
    "\n",
    "print(original + generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
