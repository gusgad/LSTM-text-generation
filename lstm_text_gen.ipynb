{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Activation, Dropout, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "# to later delete \"optimizer_weights\" part of the model weights\n",
    "# due to errors that occur when training on gpu and testing on cpu\n",
    "import h5py\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('Modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists from the lyrics for 57650 songs. The data has been acquired from LyricsFreak through scraping. Then some very basic work has been done on removing inconvenient data: non-English lyrics, extremely short and extremely long lyrics, lyrics with non-ASCII symbols. The dataset contains 4 columns:\n",
    "\n",
    "* Artist\n",
    "* Song Name\n",
    "* Link to a webpage with the song (for reference). This is to be concatenated with http://www.lyricsfreak.com to form a real URL.\n",
    "* Lyrics of the song, unmodified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/songdata.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 68056106\n",
      "Example text: look at her face, it's a wonderful face  \n",
      "and it means something special to me  \n",
      "look at the way that she smiles when she sees me  \n",
      "how lucky can one fellow be?  \n",
      "  \n",
      "she's just my kind of girl, she makes me feel fine  \n",
      "who could ever believe that she could be mine?  \n",
      "she's just my kind of girl, with\n"
     ]
    }
   ],
   "source": [
    "corpus = data['text'].str.cat(sep='\\n').lower()\n",
    "print('Corpus length:', len(corpus))\n",
    "print('Example text:', corpus[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated corpus length: 1000000\n"
     ]
    }
   ],
   "source": [
    "# truncating the corpus\n",
    "# since it is going to take too long to train\n",
    "corpus = corpus[:1000000]\n",
    "print('Truncated corpus length:', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 50\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# creating a character vocabulary\n",
    "chars = sorted(list(set(corpus)))\n",
    "print('Total chars:', len(chars))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating lookup dictionaries\n",
    "char_to_ind = dict((c, i) for i, c in enumerate(chars))\n",
    "ind_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40 # the window size\n",
    "step = 3 # step of the window\n",
    "sentences = []\n",
    "next_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of sentences: (333320,)\n",
      "[\"look at her face, it's a wonderful face \"\n",
      " \"k at her face, it's a wonderful face  \\na\"\n",
      " \"t her face, it's a wonderful face  \\nand \" ...,\n",
      " \"t that we're less worse  \\n  \\ntears are n\"\n",
      " \"hat we're less worse  \\n  \\ntears are not \"\n",
      " \" we're less worse  \\n  \\ntears are not eno\"]\n",
      "[' ' 'n' 'i' ..., 'o' 'e' 'u']\n"
     ]
    }
   ],
   "source": [
    "# sentences as features, next chars as labels\n",
    "for i in range(0, len(corpus) - maxlen, step):\n",
    "    sentences.append(corpus[i: i + maxlen]) # range from current index i for max length characters \n",
    "    next_chars.append(corpus[i + maxlen]) # the next character after that \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "print('Shape of sentences:', sentences.shape)\n",
    "print(sentences)\n",
    "print(next_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer encoded X: [192992 181993 264233 ..., 266428 157152  73624]\n",
      "Integer encoded y: [ 1 37 32 ..., 38 28 44]\n"
     ]
    }
   ],
   "source": [
    "# convert each character to categorical numbers\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_X = label_encoder.fit_transform(sentences)\n",
    "integer_encoded_y = label_encoder.fit_transform(next_chars)\n",
    "\n",
    "print('Integer encoded X:', integer_encoded_X)\n",
    "print('Integer encoded y:', integer_encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-164a893bb629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minteger_encoded_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0monehot_encoded_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minteger_encoded_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteger_encoded_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteger_encoded_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \"\"\"\n\u001b[1;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 2019\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;31m##############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/conda/envs/lstm-text-gen/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# one-hot encode each categorical number\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "integer_encoded_X = integer_encoded_X.reshape(len(integer_encoded_X), 1)\n",
    "onehot_encoded_X = onehot_encoder.fit_transform(integer_encoded_X)\n",
    "\n",
    "integer_encoded_y = integer_encoded_y.reshape(len(integer_encoded_y), 1)\n",
    "onehot_encoded_y = onehot_encoder.fit_transform(integer_encoded_y)\n",
    "\n",
    "\n",
    "print(onehot_encoded_X, onehot_encoded_y)\n",
    "\n",
    "X = onehot_encoded_X\n",
    "y = onehot_encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding the input values wrapped in a separate function,\n",
    "# since the dataset length causes the memory error (on my machine) when converting all at once\n",
    "def encode(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_to_ind[char]] = 1\n",
    "        y[i, char_to_ind[next_chars[i]]] = 1\n",
    "    return X, y\n",
    "\n",
    "X, y = encode(sentences, next_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 98,098\n",
      "Trainable params: 98,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "# NOTE:TRAIN AND TEST 1 MODEL AT A TIME\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 114,610\n",
      "Trainable params: 114,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model 2\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model2.add(Dense(128))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(len(chars)))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training checkpoints\n",
    "filepath=\"weights_model2{epoch:02d}-{loss:.4f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4622Epoch 00000: loss improved from 1.51919 to 1.46217, saving model to weights_model200-1.4622.h5\n",
      "333320/333320 [==============================] - 1489s - loss: 1.4622  \n",
      "Epoch 2/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4420Epoch 00001: loss improved from 1.46217 to 1.44198, saving model to weights_model201-1.4420.h5\n",
      "333320/333320 [==============================] - 1489s - loss: 1.4420  \n",
      "Epoch 3/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4232Epoch 00002: loss improved from 1.44198 to 1.42318, saving model to weights_model202-1.4232.h5\n",
      "333320/333320 [==============================] - 1493s - loss: 1.4232  \n",
      "Epoch 4/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.4079Epoch 00003: loss improved from 1.42318 to 1.40790, saving model to weights_model203-1.4079.h5\n",
      "333320/333320 [==============================] - 1512s - loss: 1.4079  \n",
      "Epoch 5/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3951Epoch 00004: loss improved from 1.40790 to 1.39512, saving model to weights_model204-1.3951.h5\n",
      "333320/333320 [==============================] - 1514s - loss: 1.3951  \n",
      "Epoch 6/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3838Epoch 00005: loss improved from 1.39512 to 1.38385, saving model to weights_model205-1.3838.h5\n",
      "333320/333320 [==============================] - 1519s - loss: 1.3838  \n",
      "Epoch 7/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3724Epoch 00006: loss improved from 1.38385 to 1.37243, saving model to weights_model206-1.3724.h5\n",
      "333320/333320 [==============================] - 1519s - loss: 1.3724  \n",
      "Epoch 8/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3636Epoch 00007: loss improved from 1.37243 to 1.36361, saving model to weights_model207-1.3636.h5\n",
      "333320/333320 [==============================] - 1521s - loss: 1.3636  \n",
      "Epoch 9/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3556Epoch 00008: loss improved from 1.36361 to 1.35554, saving model to weights_model208-1.3555.h5\n",
      "333320/333320 [==============================] - 1525s - loss: 1.3555  \n",
      "Epoch 10/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3466Epoch 00009: loss improved from 1.35554 to 1.34658, saving model to weights_model209-1.3466.h5\n",
      "333320/333320 [==============================] - 1525s - loss: 1.3466  \n",
      "Epoch 11/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3417Epoch 00010: loss improved from 1.34658 to 1.34166, saving model to weights_model210-1.3417.h5\n",
      "333320/333320 [==============================] - 1530s - loss: 1.3417  \n",
      "Epoch 12/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3367Epoch 00011: loss improved from 1.34166 to 1.33673, saving model to weights_model211-1.3367.h5\n",
      "333320/333320 [==============================] - 1804s - loss: 1.3367  \n",
      "Epoch 13/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3309Epoch 00012: loss improved from 1.33673 to 1.33090, saving model to weights_model212-1.3309.h5\n",
      "333320/333320 [==============================] - 1510s - loss: 1.3309  \n",
      "Epoch 14/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3259Epoch 00013: loss improved from 1.33090 to 1.32589, saving model to weights_model213-1.3259.h5\n",
      "333320/333320 [==============================] - 1597s - loss: 1.3259  \n",
      "Epoch 15/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3225Epoch 00014: loss improved from 1.32589 to 1.32247, saving model to weights_model214-1.3225.h5\n",
      "333320/333320 [==============================] - 1650s - loss: 1.3225  \n",
      "Epoch 16/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3167Epoch 00015: loss improved from 1.32247 to 1.31669, saving model to weights_model215-1.3167.h5\n",
      "333320/333320 [==============================] - 1631s - loss: 1.3167  \n",
      "Epoch 17/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3145Epoch 00016: loss improved from 1.31669 to 1.31452, saving model to weights_model216-1.3145.h5\n",
      "333320/333320 [==============================] - 1580s - loss: 1.3145  \n",
      "Epoch 18/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3110Epoch 00017: loss improved from 1.31452 to 1.31102, saving model to weights_model217-1.3110.h5\n",
      "333320/333320 [==============================] - 1573s - loss: 1.3110  \n",
      "Epoch 19/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3070- ETA: 1s - loss: Epoch 00018: loss improved from 1.31102 to 1.30702, saving model to weights_model218-1.3070.h5\n",
      "333320/333320 [==============================] - 1574s - loss: 1.3070  \n",
      "Epoch 20/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3028Epoch 00019: loss improved from 1.30702 to 1.30286, saving model to weights_model219-1.3029.h5\n",
      "333320/333320 [==============================] - 1579s - loss: 1.3029  \n",
      "Epoch 21/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.3005- ETAEpoch 00020: loss improved from 1.30286 to 1.30049, saving model to weights_model220-1.3005.h5\n",
      "333320/333320 [==============================] - 1581s - loss: 1.3005  \n",
      "Epoch 22/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.29655 ETA: 10s - loss: 1 - ETA: 4s - loss: 1. - ETA:Epoch 00021: loss improved from 1.30049 to 1.29655, saving model to weights_model221-1.2966.h5\n",
      "333320/333320 [==============================] - 1586s - loss: 1.2966  \n",
      "Epoch 23/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2939Epoch 00022: loss improved from 1.29655 to 1.29393, saving model to weights_model222-1.2939.h5\n",
      "333320/333320 [==============================] - 1588s - loss: 1.2939  \n",
      "Epoch 24/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2922- ETA: 3s - loss: - ETA: 2s - loss: 1.292 - ETA: 2s - loEpoch 00023: loss improved from 1.29393 to 1.29215, saving model to weights_model223-1.2921.h5\n",
      "333320/333320 [==============================] - 1589s - loss: 1.2921  \n",
      "Epoch 25/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2908- ETA: 4s - loss: 1. - ETA: Epoch 00024: loss improved from 1.29215 to 1.29080, saving model to weights_model224-1.2908.h5\n",
      "333320/333320 [==============================] - 1594s - loss: 1.2908  \n",
      "Epoch 26/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2876Epoch 00025: loss improved from 1.29080 to 1.28764, saving model to weights_model225-1.2876.h5\n",
      "333320/333320 [==============================] - 1594s - loss: 1.2876  \n",
      "Epoch 27/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2864Epoch 00026: loss improved from 1.28764 to 1.28642, saving model to weights_model226-1.2864.h5\n",
      "333320/333320 [==============================] - 1535s - loss: 1.2864  \n",
      "Epoch 28/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2859Epoch 00027: loss improved from 1.28642 to 1.28589, saving model to weights_model227-1.2859.h5\n",
      "333320/333320 [==============================] - 1535s - loss: 1.2859  \n",
      "Epoch 29/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2846Epoch 00028: loss improved from 1.28589 to 1.28467, saving model to weights_model228-1.2847.h5\n",
      "333320/333320 [==============================] - 1540s - loss: 1.2847  \n",
      "Epoch 30/30\n",
      "333312/333320 [============================>.] - ETA: 0s - loss: 1.2812- ETA: 3Epoch 00029: loss improved from 1.28467 to 1.28121, saving model to weights_model229-1.2812.h5\n",
      "333320/333320 [==============================] - 1528s - loss: 1.2812  \n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 42\n",
    "\n",
    "trained = model2.fit(X, y, batch_size, epochs=30, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: run this if the model is trained on gpu but being tested on cpu\n",
    "# RUN ONCE FOR A FILE\n",
    "f = h5py.File('weights29-1.1538.h5', 'r+')\n",
    "del f['optimizer_weights']\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length: 40\n",
      "Predictions per char in vocabulary [[  1.71119809e-05   3.55375111e-02   3.41021769e-06   3.78997298e-04\n",
      "    3.98959179e-04   2.78970995e-03   1.24004885e-06   1.13178930e-05\n",
      "    1.01340382e-04   6.87545935e-06   2.05232845e-06   1.37025680e-04\n",
      "    1.05412648e-04   4.65848598e-06   5.19655487e-06   6.08608207e-06\n",
      "    2.02593510e-04   1.84048508e-06   5.33222192e-06   1.71361007e-05\n",
      "    3.25404312e-06   5.19605201e-05   5.64325564e-05   4.10753501e-07\n",
      "    1.92759149e-02   9.45081562e-02   3.21600474e-02   2.19398439e-02\n",
      "    1.06698321e-02   3.52355726e-02   4.42303494e-02   9.67846066e-02\n",
      "    3.11897211e-02   9.77126230e-03   2.41910759e-02   1.64146617e-01\n",
      "    1.20490817e-02   3.38718249e-03   6.52648415e-03   3.67834084e-02\n",
      "    1.99042726e-03   1.12015735e-02   1.44536838e-01   7.38101080e-02\n",
      "    7.27118109e-04   6.28432550e-04   3.59937400e-02   4.56165872e-05\n",
      "    4.82902229e-02   8.08818659e-05]]\n"
     ]
    }
   ],
   "source": [
    "# example test phrase\n",
    "sentence = 'wise men say only fools rush in but can '\n",
    "sentence = sentence.lower()\n",
    "print('Sentence length:', len(sentence))\n",
    "\n",
    "# construct a vector from an example phrase\n",
    "x = np.zeros((1, maxlen, len(chars)))\n",
    "for i, char in enumerate(sentence):\n",
    "    x[0, i, char_to_ind[char]] = 1.\n",
    "    \n",
    "# load trained weights\n",
    "model = load_model('weights29-1.1538.h5')\n",
    "\n",
    "\n",
    "print('Predictions per char in vocabulary', model.predict(x, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: adding randomness for choosing predicted characters\n",
    "def sample(preds, temperature):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature:  0.8\n",
      "wise men say only fools rush in but can be sall  \n",
      "i have the smappeat leed me  \n",
      "  \n",
      "shine chasing two the man and then you ever fidds  \n",
      "home is so on the tears  \n",
      "freemonts my show  \n",
      "i want to midnide me and the strousing for a get a boy trought  \n",
      "give me on the tile is just only money, jeen, more that spine mingin' rifer  \n",
      "the mount, and the selt time we till in the couls sidenth  \n",
      "there's no breath me to the bould say  \n",
      "goodollin' at the even cake the morning  \n",
      "it's slowd when prectory  \n",
      "and but there's too find  \n",
      "i stop myse the dest\n"
     ]
    }
   ],
   "source": [
    "# temperature defines randomness rate for using predictions\n",
    "temperature = 0.8\n",
    "print('Temperature: ', temperature)\n",
    "\n",
    "generated = ''\n",
    "original = sentence\n",
    "window = sentence\n",
    "\n",
    "# predicting next 500 chars\n",
    "for i in range(500):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(window):\n",
    "        x[0, t, char_to_ind[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = ind_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    window = window[1:] + next_char\n",
    "\n",
    "print(original + generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
